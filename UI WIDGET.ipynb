{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification demo including training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "## Convolution(64 feature detector of dimension 3 by 3), input shape 3 layer for color image)\n",
    "classifier.add(Conv2D(64,(3,3),input_shape = (64,64,3), activation = 'relu'))\n",
    "## MaxPooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "## Add another layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully connected ANN, Hidden ANN and output layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "classifier.add(Dense(units = 11, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compliling\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 405,131\n",
      "Trainable params: 405,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data importing and transforming and scaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling test data\n",
    "##no  data augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7040 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importing training data\n",
    "train_set = train_datagen.flow_from_directory('training_set',\n",
    "                                               target_size=(64, 64),\n",
    "                                               batch_size=30,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cards': 0,\n",
       " 'checkbox': 1,\n",
       " 'combobox': 2,\n",
       " 'enable_disable': 3,\n",
       " 'forward': 4,\n",
       " 'home': 5,\n",
       " 'information_icon': 6,\n",
       " 'tabview': 7,\n",
       " 'textbox': 8,\n",
       " 'window_header': 9,\n",
       " 'zoom': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cards': 0, 'checkbox': 1, 'combobox': 2, 'enable_disable': 3, 'forward': 4, 'home': 5, 'information_icon': 6, 'tabview': 7, 'textbox': 8, 'window_header': 9, 'zoom': 10}\n"
     ]
    }
   ],
   "source": [
    "#which is cat which is dog?\n",
    "label_map = (train_set.class_indices)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "## Importng test data\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=30,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.6946 - acc: 0.7675 - val_loss: 0.2399 - val_acc: 0.9191\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 12s 311ms/step - loss: 0.1091 - acc: 0.9683 - val_loss: 0.2006 - val_acc: 0.9580\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 11s 278ms/step - loss: 0.0593 - acc: 0.9917 - val_loss: 0.1300 - val_acc: 0.9730\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 0.0377 - acc: 0.9917 - val_loss: 0.0987 - val_acc: 0.9727\n",
      "Epoch 5/15\n",
      " 8/40 [=====>........................] - ETA: 7s - loss: 0.0784 - acc: 0.9792Epoch 10/15\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.0399 - acc: 0.9900 - val_loss: 0.0505 - val_acc: 0.9831\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 12s 291ms/step - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0512 - val_acc: 0.9818\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 11s 279ms/step - loss: 0.0167 - acc: 0.9958 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 2.8010e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9966\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 0.0023 - acc: 0.9983 - val_loss: 0.0159 - val_acc: 0.9920\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 11s 278ms/step - loss: 0.0100 - acc: 0.9983 - val_loss: 0.0441 - val_acc: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29549178940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting model to images\n",
    "classifier.fit_generator(\n",
    "        train_set,validation_data= test_set,\n",
    "        validation_steps=30,\n",
    "        steps_per_epoch=40,\n",
    "        epochs = 15\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : check1.jpg--------------------------->Predicted : checkbox\n",
      "Original : check2.jpg--------------------------->Predicted : cards\n",
      "Original : combo_box.jpg--------------------------->Predicted : cards\n",
      "Original : drop1.jpg--------------------------->Predicted : cards\n",
      "Original : drop2.jpg--------------------------->Predicted : cards\n",
      "Original : enable1.jpg--------------------------->Predicted : checkbox\n",
      "Original : enable2.png--------------------------->Predicted : zoom\n",
      "Original : enable3.png--------------------------->Predicted : cards\n",
      "Original : home1.png--------------------------->Predicted : cards\n",
      "Original : home2.jpg--------------------------->Predicted : forward\n",
      "Original : info_icon1.png--------------------------->Predicted : information_icon\n",
      "Original : info_icon2.jpg--------------------------->Predicted : cards\n",
      "Original : tab1.png--------------------------->Predicted : cards\n",
      "Original : text1.jpg--------------------------->Predicted : cards\n",
      "Original : wh1.jpg--------------------------->Predicted : cards\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "os.chdir(\"C:\\\\Users\\\\Administrator\\\\AI\\\\UI-widget-casestudy\\\\inference\")\n",
    "for filename in os.listdir():\n",
    "    i=image.load_img(filename,target_size=(64,64))\n",
    "    i=image.img_to_array(i)\n",
    "    i=i.reshape((1,i.shape[0],i.shape[1],i.shape[2]))\n",
    "    \n",
    "    result = classifier.predict(i)\n",
    "    result=np.argmax(result)\n",
    "    \n",
    "    if result == 0:\n",
    "        prediction = 'cards'\n",
    "    elif result == 1:\n",
    "        prediction = 'checkbox'\n",
    "    elif result == 2: \n",
    "        prediction = 'combobox'\n",
    "    elif result == 3: \n",
    "        prediction = 'enable_disable'\n",
    "    elif result == 4: \n",
    "        prediction = 'forward'\n",
    "    elif result == 5: \n",
    "        prediction = 'home'\n",
    "    elif result == 6: \n",
    "        prediction = 'information_icon'\n",
    "    elif result == 7: \n",
    "        prediction = 'tabview'\n",
    "    elif result == 8: \n",
    "        prediction = 'textbox'\n",
    "    elif result == 9: \n",
    "        prediction = 'window_header'\n",
    "    else:\n",
    "        prediction = 'zoom'\n",
    "    \n",
    "    print(\"Original :\",filename,end=\"--------------------------->\")\n",
    "\n",
    "    print(\"Predicted :\",prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
